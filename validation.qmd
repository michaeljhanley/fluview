---
title: "FluView Data Validation"
format: html
editor: visual
---

Install & load dependencies

```{r}
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(tidyverse, lubridate, readxl, nanoparquet, visdat, dlookr, validate, naniar, usethis, purrr)
```

Load path name from .Renviron
{-} TO-DO: Double-check after changing over to API pull instead of CSV

```{r}
data_dir <- Sys.getenv("DATA_DIR")
if (data_dir == "") stop("DATA_DIR environment variable is not set")
file_path <- file.path(data_dir, "raw_test_data.csv")
if (!file.exists(file_path)) stop("File does not exist at the given path.")
```

Open file into a tibble, glimpse to confirm:

```{r}
data <- read_csv(file_path)
glimpse(data)
```

Initial diagnoses

```{r}
diagnose(data)
```

```{r}
diagnose_outlier(data)
```

Column "num_age_2" is of type <lgl>, so let's double-check to see if every value is NA

```{r}
all(is.na(data$num_age_2))
```

Dropping "num_age_2" because all values are NA

```{r}
data <- select(data, -num_age_2)
glimpse(data)
```

Loop through columns and sort them by type

```{r}
categorize_columns <- function(df) {
  col_types <- list()
  
  for (col in names(df)) {
    col_type <- class(df[[col]])[1]  # Take the first class if multiple
    
    if (!col_type %in% names(col_types)) {
      col_types[[col_type]] <- c()
    }
    
    col_types[[col_type]] <- c(col_types[[col_type]], col)
  }
  
  # Remove empty categories
  col_types <- col_types[sapply(col_types, length) > 0]
  
  # Print summary information
  cat("Column types present in the dataframe:\n")
  for (type in names(col_types)) {
    cat(sprintf("- %s: %d columns stored in variable `%s_cols`\n", 
                type, length(col_types[[type]]), type))
  }
  
  return(col_types)
}

categorized_columns <- categorize_columns(data)
print(categorized_columns)
```

Recast to-do list:
[x] $Date to dttm
[x] $character to factor
[x] Some $numeric to integer

Convert $Date columns to lubridate POSIXct in ymd format for validation

```{r}
data <- data %>%
  mutate(across(all_of(categorized_columns$Date), 
                ~as.POSIXct(ymd(.))))
```

View unique values in "region" category column to ensure categorical constraints

```{r}
unique(data$region)
```

No unexpected values found. Convert $character column to factors

```{r}
data <- data %>%
  mutate(across(all_of(categorized_columns$character), 
                ~as_factor(.)))
```

Loop through numeric columns to see if they can be converted to integers in cleaning.
Initializing with a vector instead of a list because we're only looping through 15 elements max

```{r}
convert_to_integers <- character()

for (numeric_column in categorized_columns$numeric) {
  if (all(round(data[[numeric_column]]) == data[[numeric_column]] & !is.na(data[[numeric_column]]))) {
    convert_to_integers <- c(convert_to_integers, numeric_column)
  }
}

print(convert_to_integers)
```

Visualize outliers for all numeric columns using histograms

```{r}
plots <- purrr::map(categorized_columns$numeric, function(col) {
  # Calculate IQR boundaries
  q1 <- quantile(data[[col]], 0.25, na.rm = TRUE)
  q3 <- quantile(data[[col]], 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  iqr_lower <- q1 - 1.5 * iqr
  iqr_upper <- q3 + 1.5 * iqr
  
  # Calculate 3-sigma boundaries
  mean_val <- mean(data[[col]], na.rm = TRUE)
  sd_val <- sd(data[[col]], na.rm = TRUE)
  sigma_lower <- mean_val - 3 * sd_val
  sigma_upper <- mean_val + 3 * sd_val
  
  ggplot(data) +
    geom_histogram(aes(x = .data[[col]]), bins = 30, fill = "steelblue", color = "white") +
    # Add IQR rule lines in red
    geom_vline(xintercept = c(iqr_lower, iqr_upper), 
               color = "red", linetype = "dashed", linewidth = 1) +
    # Add 3-sigma rule lines in green
    geom_vline(xintercept = c(sigma_lower, sigma_upper), 
               color = "darkgreen", linetype = "dashed", linewidth = 1) +
    labs(title = paste("Distribution of", col),
         subtitle = "Red: IQR outlier bounds | Green: 3-sigma bounds",
         x = col,
         y = "Count") +
    theme_minimal()
})
plots
```

All of these look expected, though the blip on num_patients is worth exploring

```{r}
# Calculate IQR boundaries
q1 <- quantile(data$num_providers, 0.25, na.rm = TRUE)
q3 <- quantile(data$num_providers, 0.75, na.rm = TRUE)
iqr <- q3 - q1
iqr_lower <- q1 - 1.5 * iqr
iqr_upper <- q3 + 1.5 * iqr

# Calculate 3-sigma boundaries
mean_val <- mean(data$num_providers, na.rm = TRUE)
sd_val <- sd(data$num_providers, na.rm = TRUE)
sigma_lower <- mean_val - 3 * sd_val
sigma_upper <- mean_val + 3 * sd_val

# Time series plot
time_plot <- ggplot(data) +
  geom_line(aes(x = epiweek, y = num_providers), color = "steelblue") +
  # Add IQR bounds
  geom_hline(yintercept = c(iqr_lower, iqr_upper), 
             color = "red", linetype = "dashed", linewidth = 1) +
  # Add 3-sigma bounds
  geom_hline(yintercept = c(sigma_lower, sigma_upper), 
             color = "darkgreen", linetype = "dashed", linewidth = 1) +
  # Highlight outlier points
  geom_point(data = data %>% 
               filter(num_providers > iqr_upper | num_providers < iqr_lower),
             aes(x = epiweek, y = num_providers),
             color = "red", size = 3) +
  labs(title = "Healthcare Providers Over Time",
       subtitle = "Red: IQR outlier bounds | Green: 3-sigma bounds",
       x = "Epiweek",
       y = "Number of Providers") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Added angle for better readability

time_plot
```

All of the outliers appear to have happened in 2019. Let's come back to this in EDA

Identify duplicates, if any

```{r}
data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup() %>%
  print()
```

No duplicate rows found.

Misc. remaining validation tasks:

[x] String length violations (region has to be 5 or less characters)
[x] Number range constraints (none of our numeric columns can be negative)
[x] Cross-field validation (num_ili has to equal sum of age 0 through 5)
[x] Start and end date validation (Data can't be before week 40 of 2014)

```{r}
# Misc. validation config
year_start <- 2014
epiweek_start <- 40
numeric_column_floor <- 0

# Validator object & check
rules <- validator(
  release_date = epiweek(release_date) >= epiweek_start | year(release_date) > year_start,
  epiweek = epiweek(epiweek) >= epiweek_start | year(epiweek) > year_start,
  issue = epiweek(issue) >= epiweek_start | year(issue) > year_start,
  num_ili_sums = num_ili == num_age_0 + num_age_1 + num_age_3 + num_age_4 + num_age_5,
  lag = lag >= numeric_column_floor,
  num_ili = num_ili >= numeric_column_floor,
  patients = num_patients >= numeric_column_floor, 
  providers = num_providers >= numeric_column_floor,
  age_0 = num_age_0 >= numeric_column_floor,
  age_1 = num_age_1 >= numeric_column_floor, 
  age_3 = num_age_3 >= numeric_column_floor,
  age_4 = num_age_4 >= numeric_column_floor,
  age_5 = num_age_5 >= numeric_column_floor,
  wili = wili >= numeric_column_floor,
  ili = ili >= numeric_column_floor,
  region_character_length = nchar(as.character(region)) <= 5
)

check <- confront(data, rules)
summary(check)
```

Write to parquet for type preservation

```{r}
write_parquet(data, "validated_data.parquet")
```