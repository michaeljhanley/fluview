---
title: "FluView Data Validation"
format: html
editor: visual
---

Install & load dependencies

```{r}
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(tidyverse, lubridate, readxl, nanoparquet, visdat, dlookr, validate, naniar, usethis, purrr)
```

Load path name from .Renviron
{-} TO-DO: Double-check after changing over to API pull instead of CSV

```{r}
data_dir <- Sys.getenv("DATA_DIR")
if (data_dir == "") stop("DATA_DIR environment variable is not set")
file_path <- file.path(data_dir, "raw_test_data.csv")
if (!file.exists(file_path)) stop("File does not exist at the given path.")
```

Open file into a tibble, glimpse to confirm:

```{r}
data <- read_csv(file_path)
glimpse(data)
```

Initial diagnoses

```{r}
diagnose(data)
```

```{r}
diagnose_outlier(data)
```

Column "num_age_2" is of type <lgl>, so let's double-check to see if every value is NA

```{r}
all(is.na(data$num_age_2))
```

Dropping "num_age_2" because all values are NA

```{r}
data <- select(data, -num_age_2)
glimpse(data)
```

Loop through columns and sort them by type

```{r}
categorize_columns <- function(df) {
  col_types <- list()
  
  for (col in names(df)) {
    col_type <- class(df[[col]])[1]  # Take the first class if multiple
    
    if (!col_type %in% names(col_types)) {
      col_types[[col_type]] <- c()
    }
    
    col_types[[col_type]] <- c(col_types[[col_type]], col)
  }
  
  # Remove empty categories
  col_types <- col_types[sapply(col_types, length) > 0]
  
  # Print summary information
  cat("Column types present in the dataframe:\n")
  for (type in names(col_types)) {
    cat(sprintf("- %s: %d columns stored in variable `%s_cols`\n", 
                type, length(col_types[[type]]), type))
  }
  
  return(col_types)
}

categorized_columns <- categorize_columns(data)
print(categorized_columns)
```

Loop through numeric columns to see if they can be converted to integers in cleaning.
Initializing with a vector instead of a list because we're only looping through 15 elements max

```{r}
convert_to_integers <- character()

for (numeric_column in categorized_columns$numeric) {
  if (all(round(data[[numeric_column]]) == data[[numeric_column]] & !is.na(data[[numeric_column]]))) {
    convert_to_integers <- c(convert_to_integers, numeric_column)
  }
}

print(convert_to_integers)
```

Visualize outliers for all numeric columns using histograms

```{r}
plots <- purrr::map(categorized_columns$numeric, function(col) {
  # Calculate IQR boundaries
  q1 <- quantile(data[[col]], 0.25, na.rm = TRUE)
  q3 <- quantile(data[[col]], 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  iqr_lower <- q1 - 1.5 * iqr
  iqr_upper <- q3 + 1.5 * iqr
  
  # Calculate 3-sigma boundaries
  mean_val <- mean(data[[col]], na.rm = TRUE)
  sd_val <- sd(data[[col]], na.rm = TRUE)
  sigma_lower <- mean_val - 3 * sd_val
  sigma_upper <- mean_val + 3 * sd_val
  
  ggplot(data) +
    geom_histogram(aes(x = .data[[col]]), bins = 30, fill = "steelblue", color = "white") +
    # Add IQR rule lines in red
    geom_vline(xintercept = c(iqr_lower, iqr_upper), 
               color = "red", linetype = "dashed", linewidth = 1) +
    # Add 3-sigma rule lines in green
    geom_vline(xintercept = c(sigma_lower, sigma_upper), 
               color = "darkgreen", linetype = "dashed", linewidth = 1) +
    labs(title = paste("Distribution of", col),
         subtitle = "Red: IQR outlier bounds | Green: 3-sigma bounds",
         x = col,
         y = "Count") +
    theme_minimal()
})
plots
```
All of these look expected, though the blip on num_patients is worth exploring

```{r}
examine_outliers <- c("num_patients")
```

Identify duplicates, if any

```{r}
data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup() %>%
  print()
```

No duplicate rows found.

Flag "region" as a column that can be recast as factor in cleaning

```{r}
columns_to_recast <- c("region")
```

View unique values in "region" category column

```{r}
unique(data$region)
```

No unexpected values found.

Convert date columns to lubridate's Date format
Would normally 
